{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing the output of viriation\n",
    "\n",
    "The output of the Viriation program is processed through the following steps:\n",
    "1. Reading in the annotations of the mutations -> verifying/pushing changes to our database\n",
    "2. Reading in user feedback for text chunk data and literature level data -> fine-tuning BERT and LightGBM models\n",
    "3. Saving intermediary states including a) papers that have been screened through the classifier b) papers that have been annotated already c) user feedback from the annotation front-end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create intermediaries\n",
    "\n",
    "# Hashtable for managing scraping history\n",
    "scraped_papers = {\n",
    "    'relevant': set(), # papers that passed screening\n",
    "    'irrelevant': set(), # papers that were screened out + papers users said were irrelevant\n",
    "    'dates': [] # Dates that have been screened -> (start date, end date)\n",
    "}\n",
    "\n",
    "scraped_papers.append(('2000-01-01', '2022-09-31'))\n",
    "\n",
    "with open('../../data/database/history.pkl', 'wb') as f:\n",
    "    pickle.dump(scraped_papers, f)\n",
    "\n",
    "# Hashtable for managing retrain data in the self-train feature\n",
    "retrain_data = {\n",
    "    'relevant papers': set(), # Positive examples BERT\n",
    "    'irrelevant papers': set(), # Negative examples BERT\n",
    "    'relevant text': set(), # Positive examples LightGBM\n",
    "    'irrelevant text': set() # Negative examples LightGBM\n",
    "}\n",
    "\n",
    "with open('../../data/database/self_train.pkl', 'wb') as f:\n",
    "    pickle.dump(retrain_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from intervaltree import Interval, IntervalTree\n",
    "\n",
    "\n",
    "class History:\n",
    "    def __init__(self):\n",
    "        self.dates = IntervalTree() # Interval search tree with dates that have been screened -> (start date, end date)\n",
    "        self.papers = {\n",
    "            'relevant' : set(), # papers that passed screening\n",
    "            'irrelevant' : set() # papers that were screened out + papers users said were irrelevant\n",
    "        }\n",
    "\n",
    "\n",
    "    def checkDateRange(self, date_range):\n",
    "        \"\"\" \n",
    "        Determines whether the given date range overlaps with any intervals in the cache of previous scraped dates\n",
    "        \n",
    "        Parameters: \n",
    "        date_range (tuple): Date range with start date and end date\n",
    "\n",
    "        Returns:\n",
    "        bool: Whether the given date range overlaps with any previous date ranges\n",
    "        \"\"\"\n",
    "\n",
    "        start_dt, end_dt = date_range\n",
    "        start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        # Convert to timestamp (float) since intervaltree works on numeric values\n",
    "        start_ts = start_dt.timestamp()\n",
    "        end_ts = end_dt.timestamp()\n",
    "\n",
    "        # Query for overlapping intervals in the given range\n",
    "        overlapping_intervals = self.dates.overlap(start_ts, end_ts)\n",
    "\n",
    "        return bool(overlapping_intervals)\n",
    "\n",
    "\n",
    "    def addDateRange(self, date_range):\n",
    "        \"\"\"\n",
    "        Adds new date range into the cache of already scraped dates\n",
    "\n",
    "        Parameters:\n",
    "        date_range (tuple): Date range with start date and end date\n",
    "        \"\"\"\n",
    "        start_dt, end_dt = date_range\n",
    "        start_dt = datetime.strptime(start_dt, '%Y-%m-%d')\n",
    "        end_dt = end_dt = datetime.strptime(end_dt, '%Y-%m-%d')\n",
    "        \n",
    "        start_ts = start_dt.timestamp()\n",
    "        end_ts = end_dt.timestamp()\n",
    "\n",
    "        self.dates[start_ts:end_ts] = (start_dt, end_dt) # Add date range\n",
    "    \n",
    "\n",
    "    def getNonOverlap(self, date_range):\n",
    "        \"\"\" \n",
    "        Returns all dates within the given date range that are not present in the cache of previous scraped dates\n",
    "        \n",
    "        Parameters: \n",
    "        date_range (tuple): Date range with start date and end date\n",
    "\n",
    "        Returns:\n",
    "        list: list of tuples consisting of date ranges that have not been scraped yet\n",
    "        \"\"\"\n",
    "        start_dt, end_dt = date_range\n",
    "        start_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "        end_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "        \n",
    "        # Convert to timestamp (float) since intervaltree works on numeric values\n",
    "        start_ts = start_dt.timestamp()\n",
    "        end_ts = end_dt.timestamp()\n",
    "\n",
    "        # Query for overlapping intervals in the given range\n",
    "        overlapping_intervals = self.dates.overlap(start_ts, end_ts)\n",
    "\n",
    "        if not overlapping_intervals:\n",
    "            return date_range\n",
    "        \n",
    "        overlapping_intervals = sorted(overlapping_intervals)\n",
    "        non_overlapping_ranges = []\n",
    "        current_start = start_ts\n",
    "\n",
    "        # Iterate over each overlapping interval and calculate gaps\n",
    "        for interval in overlapping_intervals:\n",
    "            if current_start < interval.begin:\n",
    "                # There is a gap between the current start and the beginning of this interval\n",
    "                non_overlapping_ranges.append((current_start, interval.begin))\n",
    "            # Update current start to the end of the current interval\n",
    "            current_start = max(current_start, interval.end)\n",
    "        \n",
    "        # Check if there's a gap after the last interval\n",
    "        if current_start < end_ts:\n",
    "            non_overlapping_ranges.append((current_start, end_ts))\n",
    "        \n",
    "        # Convert timestamps back to datetime\n",
    "        non_overlapping_ranges_dt = [\n",
    "            (datetime.fromtimestamp(start), datetime.fromtimestamp(end))\n",
    "            for start, end in non_overlapping_ranges\n",
    "        ]\n",
    "\n",
    "        return non_overlapping_ranges_dt\n",
    "\n",
    "\n",
    "    def updateTree(self):\n",
    "        \"\"\" \n",
    "        Merges all overlapping date ranges within the current cache of scraped dates\n",
    "        \"\"\"\n",
    "\n",
    "        self.dates.merge_overlaps() # merge together overlapping intervals\n",
    "        \n",
    "\n",
    "    def updatePapers(self, relevant_papers, irrelevant_papers):\n",
    "        \"\"\" \n",
    "        Updates history of relevant and irrelevant papers that have been processed through the viriation program thus far\n",
    "        \n",
    "        Parameters: \n",
    "        relevant_papers (set): Hashset consisting of the DOIs for relevant papers\n",
    "        irrelevant_papers (set): Hashset consisting of the DOIs for irrelevant papers\n",
    "        \"\"\"\n",
    "\n",
    "        for paper in relevant_papers:\n",
    "            self.papers['relevant'].add(paper)\n",
    "        for paper in irrelevant_papers:\n",
    "            self.papers['irrelevant'].add(paper)\n",
    "        \n",
    "\n",
    "    def checkPaper(self, paper):\n",
    "        \"\"\" \n",
    "        Checks whether or not a specific paper has been processed by our program before\n",
    "        \n",
    "        Parameters: \n",
    "        paper (str): DOI of paper\n",
    "\n",
    "        Returns:\n",
    "        bool: Whether the paper has been processed by our program before\n",
    "        \"\"\"\n",
    "\n",
    "        return paper in self.papers['relevant'] or paper in self.papers['irrelevant']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\n",
      "                             [-k TESTNAMEPATTERNS]\n",
      "                             [tests ...]\n",
      "ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/home/david.yang1/.local/share/jupyter/runtime/kernel-v2-2101004vJGSFL63vfa6.json'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:1902\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1902\u001b[0m     namespace, args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_known_args(args, namespace)\n\u001b[1;32m   1903\u001b[0m \u001b[39mexcept\u001b[39;00m ArgumentError \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:2114\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2113\u001b[0m     \u001b[39m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[0;32m-> 2114\u001b[0m     start_index \u001b[39m=\u001b[39m consume_optional(start_index)\n\u001b[1;32m   2116\u001b[0m \u001b[39m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:2036\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2035\u001b[0m         msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39mignored explicit argument \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2036\u001b[0m         \u001b[39mraise\u001b[39;00m ArgumentError(action, msg \u001b[39m%\u001b[39m explicit_arg)\n\u001b[1;32m   2038\u001b[0m \u001b[39m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[1;32m   2039\u001b[0m \u001b[39m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m \u001b[39m# if successful, exit the loop\u001b[39;00m\n\u001b[1;32m   2041\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument -f/--failfast: ignored explicit argument '/home/david.yang1/.local/share/jupyter/runtime/kernel-v2-2101004vJGSFL63vfa6.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[13], line 79\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 79\u001b[0m     unittest\u001b[39m.\u001b[39;49mmain()\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/unittest/main.py:101\u001b[0m, in \u001b[0;36mTestProgram.__init__\u001b[0;34m(self, module, defaultTest, argv, testRunner, testLoader, exit, verbosity, failfast, catchbreak, buffer, warnings, tb_locals)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogName \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(argv[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> 101\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparseArgs(argv)\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunTests()\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/unittest/main.py:136\u001b[0m, in \u001b[0;36mTestProgram.parseArgs\u001b[0;34m(self, argv)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_main_parser\u001b[39m.\u001b[39;49mparse_args(argv[\u001b[39m1\u001b[39;49m:], \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtests:\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:1869\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_args\u001b[39m(\u001b[39mself\u001b[39m, args\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, namespace\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1869\u001b[0m     args, argv \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_known_args(args, namespace)\n\u001b[1;32m   1870\u001b[0m     \u001b[39mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:1904\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[39mexcept\u001b[39;00m ArgumentError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 1904\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(\u001b[39mstr\u001b[39;49m(err))\n\u001b[1;32m   1905\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:2630\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2629\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[0;32m-> 2630\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[0;32m~/miniconda3/envs/viriation/lib/python3.11/argparse.py:2617\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m-> 2617\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2145\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[1;32m   2143\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   2144\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 2145\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[1;32m   2146\u001b[0m                                                      value))\n\u001b[1;32m   2147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2149\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcontains_exceptiongroup\u001b[39m(val):\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[1;32m    703\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \n\u001b[1;32m    705\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    565\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[1;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    567\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m    569\u001b[0m             etype,\n\u001b[1;32m    570\u001b[0m             evalue,\n\u001b[1;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[1;32m    573\u001b[0m             context,\n\u001b[1;32m    574\u001b[0m         )\n\u001b[1;32m    575\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[1;32m    576\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[1;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:1454\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1453\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[0;32m-> 1454\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1455\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1456\u001b[0m )\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:1345\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1342\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[1;32m   1343\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[1;32m   1344\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[1;32m   1346\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[1;32m   1347\u001b[0m     )\n\u001b[1;32m   1348\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1349\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:1192\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1185\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[1;32m   1190\u001b[0m ):\n\u001b[1;32m   1191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m   1193\u001b[0m                                                            tb_offset)\n\u001b[1;32m   1195\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:1082\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[1;32m   1080\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[1;32m   1081\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1082\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[1;32m   1083\u001b[0m )\n\u001b[1;32m   1085\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[1;32m   1086\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/autolit/viriation/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py:1150\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1150\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[1;32m   1151\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1152\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "# Unit test for History class\n",
    "\n",
    "import unittest\n",
    "from datetime import datetime\n",
    "\n",
    "class TestHistory(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"Setup a History object and add some initial data.\"\"\"\n",
    "        self.history = History()\n",
    "\n",
    "        # Add initial date ranges\n",
    "        self.history.addDateRange(('2024-01-01', '2024-01-10'))\n",
    "        self.history.addDateRange(('2024-02-15', '2024-02-20'))\n",
    "\n",
    "        # Add some papers\n",
    "        self.history.updatePapers({'paper_001', 'paper_002'}, {'paper_003', 'paper_004'})\n",
    "\n",
    "    # def test_add_date_range(self):\n",
    "    #     \"\"\"Test adding a date range and checking for overlap.\"\"\"\n",
    "    #     self.history.addDateRange(('2024-03-01', '2024-03-05'))\n",
    "    #     # Check if the date range was added properly\n",
    "    #     self.assertTrue(self.history.checkDateRange(('2024-03-01', '2024-03-05')))\n",
    "    \n",
    "    # def test_check_date_range_overlap(self):\n",
    "    #     \"\"\"Test checking if date range overlaps with existing intervals.\"\"\"\n",
    "    #     # This date range overlaps with the first range ('2024-01-01', '2024-01-10')\n",
    "    #     self.assertTrue(self.history.checkDateRange(('2024-01-05', '2024-01-12')))\n",
    "\n",
    "    #     # This date range does not overlap with any existing ranges\n",
    "    #     self.assertFalse(self.history.checkDateRange(('2024-01-11', '2024-01-12')))\n",
    "\n",
    "    # def test_get_non_overlap(self):\n",
    "    #     \"\"\"Test retrieving the non-overlapping part of a date range.\"\"\"\n",
    "    #     # This range overlaps with ('2024-01-01', '2024-01-10'), the non-overlapping part should be '2024-01-10' to '2024-01-12'\n",
    "    #     non_overlapping = self.history.getNonOverlap(('2024-01-05', '2024-01-12'))\n",
    "    #     expected_non_overlap = [(datetime(2024, 1, 10), datetime(2024, 1, 12))]\n",
    "    #     self.assertEqual(non_overlapping, expected_non_overlap)\n",
    "\n",
    "    #     # This range doesn't overlap at all, so the entire range should be returned\n",
    "    #     non_overlapping = self.history.getNonOverlap(('2024-03-01', '2024-03-10'))\n",
    "    #     self.assertEqual(non_overlapping, [(datetime(2024, 3, 1), datetime(2024, 3, 10))])\n",
    "\n",
    "    # # def test_update_tree(self):\n",
    "    #     \"\"\"Test that merging overlapping date ranges works correctly.\"\"\"\n",
    "    #     # Add overlapping date ranges\n",
    "    #     self.history.addDateRange(('2024-01-05', '2024-01-15'))\n",
    "\n",
    "    #     # Merge overlaps\n",
    "    #     self.history.updateTree()\n",
    "\n",
    "    #     # Check that the interval has been merged properly\n",
    "    #     self.assertTrue(self.history.checkDateRange(('2024-01-01', '2024-01-15')))\n",
    "    #     self.assertFalse(self.history.checkDateRange(('2024-01-15', '2024-01-16')))\n",
    "\n",
    "    # def test_update_papers(self):\n",
    "    #     \"\"\"Test updating relevant and irrelevant papers.\"\"\"\n",
    "    #     relevant_papers = {'paper_005', 'paper_006'}\n",
    "    #     irrelevant_papers = {'paper_007'}\n",
    "\n",
    "    #     # Update paper sets\n",
    "    #     self.history.updatePapers(relevant_papers, irrelevant_papers)\n",
    "\n",
    "    #     # Check if the papers were added correctly\n",
    "    #     self.assertIn('paper_005', self.history.papers['relevant'])\n",
    "    #     self.assertIn('paper_007', self.history.papers['irrelevant'])\n",
    "\n",
    "    # def test_check_paper(self):\n",
    "    #     \"\"\"Test checking if a paper has been processed.\"\"\"\n",
    "    #     # Check for a relevant paper\n",
    "    #     self.assertTrue(self.history.checkPaper('paper_001'))\n",
    "    #     # Check for an irrelevant paper\n",
    "    #     self.assertTrue(self.history.checkPaper('paper_003'))\n",
    "    #     # Check for a paper not in the set\n",
    "    #     self.assertFalse(self.history.checkPaper('paper_008'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mutation                        DOI Location       Effect  \\\n",
      "0    H655Y  10.1101/2023.04.17.536926     None  [Homoplasy]   \n",
      "1    N679K  10.1101/2023.04.17.536926     None           []   \n",
      "2    P681H  10.1101/2023.04.17.536926     None           []   \n",
      "\n",
      "                                                Text  \n",
      "0  [While most studies focus on receptor binding ...  \n",
      "1  [While most studies focus on receptor binding ...  \n",
      "2  [While most studies focus on receptor binding ...  \n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Reading data\n",
    "files = Path('../../data/database/annotations/').glob('*/*')\n",
    "\n",
    "annotations_data = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        # Read each line (which represents a list in string format)\n",
    "        for line in f:\n",
    "            # Convert the string representation of a list to a Python list\n",
    "            record = ast.literal_eval(line.strip())  # Parse the list\n",
    "            annotations_data.append(record)  # Add it to our data list\n",
    "\n",
    "# Convert the list of lists to a DataFrame\n",
    "# Assuming the data has these columns based on your example: ['Mutation', 'DOI', 'Unknown', 'Attributes', 'Text']\n",
    "annotations_df = pd.DataFrame(annotations_data, columns=['Mutation', 'DOI', 'Location', 'Effect', 'Text'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(annotations_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Formating data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Updating data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'10.1101_2023.07.02.547076': 'irrelevant', '10.1101_2023.04.17.536926': 'relevant'}\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Paper level feedback\n",
    "\n",
    "with open('../../data/database/self-train/irrelevant_papers.pkl', 'rb') as f:\n",
    "    papers = pickle.load(f)\n",
    "\n",
    "# Create DataFrame with three columns\n",
    "irrelevant_df = pd.DataFrame(\n",
    "    list(papers.items()),  # Convert dictionary to list of tuples\n",
    "    columns=['DOI', 'Classification']  # Specify column names\n",
    ")\n",
    "\n",
    "# Display the DataFrame\n",
    "print(irrelevant_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Chunk level feedback\n",
    "files = Path('../../data/database/self-train/').glob('*.txt')\n",
    "\n",
    "chunks_data = [] # Negative examples\n",
    "\n",
    "for file in files:\n",
    "    with open(file, 'r') as f:\n",
    "        # Read each line (which represents a list in string format)\n",
    "        for line in f:\n",
    "            # record = ast.literal_eval(line.strip())  # Parse the list\n",
    "            # chunks_data.append(record)  # Add it to our data list\n",
    "            chunks_data.append([line, \"irrelevant\"])  # Add it to our data list\n",
    "\n",
    "chunks_df = pd.DataFrame(chunks_data, columns=[\"Text\", \"Classification\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
