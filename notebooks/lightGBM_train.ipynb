{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8e12eb-dd28-4274-a8be-7765e63fc33a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efca7de3-be2e-4248-be84-5a0811787c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fe4f6-d443-45c3-bfc4-4718def85787",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Process training data\n",
    "Create training data to train gradient boosting model. \n",
    "\n",
    "Example:\n",
    "| DOI | Prediction 1 | ... | Prediction n | Paper label |\n",
    "|----------|----------|----------|----------|----------|\n",
    "| doi.org/... | Chunk label 1 | ... | Chunk label n | label |\n",
    "| doi.org/... | Chunk label 1 | ... | Chunk label n | label |\n",
    "| doi.org/... | Chunk label 1 | ... | Chunk label n | label |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6963bbd7-2c46-4854-b6b4-1a28823c3ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"lightgbm.csv\") # Text chunks with labels\n",
    "labels = pd.read_csv(\"bert_dataset.csv\") # Labels for full-text papers\n",
    "\n",
    "# Combine datasets where each row consists of predictions for all text chunks in a paper and the corresponding label\n",
    "grouped = data.groupby('paper')\n",
    "\n",
    "# Maximum number of data points in any group\n",
    "max_len = max(grouped.size())\n",
    "\n",
    "# Create DataFrame with appropriate number of columns\n",
    "columns = [f'prediction_{i}' for i in range(max_len)]\n",
    "columns.append('label')\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Create rows for each paper\n",
    "for name, group in grouped:\n",
    "    predictions = group[\"prediction\"].values.astype(float)\n",
    "    label = labels.loc[name, 'label']\n",
    "    entry = np.pad(predictions, (0, max_len - len(predictions)), constant_values=np.nan)\n",
    "    entry = np.append(entry, label)\n",
    "    df.loc[name] = entry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d1bac0-461c-4bcb-ab48-59300c460b39",
   "metadata": {},
   "source": [
    "# Train model \n",
    "Train gradient boosting model using lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ea26b42e-7baf-4249-8f62-86073382c83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce6b109-d55f-4023-91b3-d8becec0cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the target column from the feature columns\n",
    "X = df.drop(columns='label')  # features\n",
    "y = df['label']               # target labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a LightGBM dataset\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_test = lgb.Dataset(X_test, label=y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d81058-09a5-4491-95f0-6d89db2bcecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters (without hyperparameter tuning)\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',  # or 'auc'\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "bst = lgb.train(params, lgb_train, num_boost_round=100, valid_sets=[lgb_train, lgb_test], callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=10),\n",
    "    ])\n",
    "\n",
    "bst.save_model('lightbgm_model.txt', num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea5e89bf-cb37-4d73-a4db-a0c9594f6daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test dataset\n",
    "predictions = bst.predict(X_test, num_iteration=bst.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79a8064d-5910-4d84-a02b-2586dbdb3c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "def compute_metrics(pred, labels):\n",
    "    labels = labels\n",
    "    preds = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0c643d0-608a-4a4a-9d05-612574cdd08d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9435483870967742,\n",
       " 'f1': 0.943089430894309,\n",
       " 'precision': 0.9354838709677419,\n",
       " 'recall': 0.9508196721311475}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc971151-6dfd-4ada-ba51-4d60a3683ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9435483870967742\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to binary predictions\n",
    "binary_predictions = [1 if pred > 0.5 else 0 for pred in predictions]\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
