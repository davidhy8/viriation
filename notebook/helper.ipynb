{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "619f8584-c5e4-4d36-a613-b14079405f18",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "Run this notebook to import helper functions for tutorial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85102636-76c1-4449-9f46-3a66bd8c2ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from metapub.convert import doi2pmid\n",
    "import requests\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import lxml.etree as ET\n",
    "import subprocess\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c1540-6eab-42e3-b28c-616d76e217ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variable\n",
    "%env NCBI_API_KEY=\"6667a919224612da1287d74ff0d3f7b5e208\"\n",
    "\n",
    "# Regex format of DOI links, mutations, blocks, and literature type\n",
    "doi_pattern = r'https:\\/\\/doi\\.org\\/[\\w/.-]+'\n",
    "mutation_pattern = r'(.*)?\\n\\n'\n",
    "block_pattern = r'(?:(?<=\\n\\n)|^)(.+?)(?=\\n\\n|\\Z)'\n",
    "literature_pattern = r'(?<=\\[)(.*?)(?=\\])'\n",
    "url_pattern_alone = r'https:\\/\\/[^\\s]+'\n",
    "url_pattern = r'https?:\\/\\/[\\w\\/.%()-]+(?=\\s*\\[[^\\]]*\\])'\n",
    "url_and_lit_pattern = r'https?:\\/\\/[\\w\\/.%()-]+\\s+\\[(.*?)\\]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a079878-5af5-4bbc-9c23-ec64d169233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize entries in Pokay\n",
    "def recategorize_pokay(directory):\n",
    "    # Dictionary of doi to BioC JSON files \n",
    "    publication_bioc = {}\n",
    "    grey_bioc = {}\n",
    "    rxiv_bioc = {}\n",
    "\n",
    "    # Dictionary of doi to pokay mutation summaries from that article\n",
    "    publication_key = defaultdict(list)\n",
    "    grey_key = defaultdict(list)\n",
    "    rxiv_key = defaultdict(list)\n",
    "    \n",
    "    # Retrieve all files from Pokay directory\n",
    "    files = Path(directory).glob('*/*')\n",
    "    \n",
    "    # Iterate through all files in the pokay directory\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "        \n",
    "            # Read file\n",
    "            file_contents = f.read()\n",
    "    \n",
    "            # Find all mutations\n",
    "            # mutations = re.findall(mutation_pattern, file_contents)\n",
    "    \n",
    "            # Find all text blocks\n",
    "            text_blocks = re.findall(block_pattern, file_contents, re.DOTALL)\n",
    "    \n",
    "            # Iterate through all text blocks\n",
    "            for text in text_blocks:\n",
    "                \n",
    "                # Find article types\n",
    "                article_type = re.findall(url_and_lit_pattern, text)\n",
    "\n",
    "                # Find url links\n",
    "                matches = re.findall(url_pattern, text)\n",
    "\n",
    "                # If no article type provided, check format of the link\n",
    "                if len(article_type)==0:\n",
    "                    url = re.search(url_pattern_alone, text)\n",
    "\n",
    "                    if url:\n",
    "                        doi = re.search(doi_pattern, url.group())\n",
    "                        \n",
    "                        # Check if it is preprint\n",
    "                        if doi:\n",
    "                            rxiv_key[doi.group()].append(text)\n",
    "                            rxiv_bioc[doi.group()] = None\n",
    "                        # Otherwise, grey literature\n",
    "                        else:\n",
    "                            grey_key[url.group()].append(text)\n",
    "                            grey_bioc[url.group()] = None\n",
    "                    continue\n",
    "                \n",
    "                for i in range(len(article_type)):\n",
    "    \n",
    "                    if \"Journal publication\" in article_type[i]:\n",
    "                        # Search for the DOI of the publication\n",
    "                        # doi = re.search(doi_pattern, text).group()\n",
    "                        doi = matches[i]\n",
    "                        publication_key[doi].append(text)\n",
    "                        publication_bioc[doi] = None\n",
    "                        \n",
    "                    elif \"Preprint\" in article_type[i]:\n",
    "                        # Check if new DOI is provided\n",
    "                        # doi = re.search(doi_pattern, article_type[-1])\n",
    "                        doi = re.search(doi_pattern, article_type[i])\n",
    "                        \n",
    "                        # Check if Rxiv is now published\n",
    "                        if doi is not None:\n",
    "                            publication_key[doi.group()].append(text)\n",
    "                            publication_bioc[doi.group()] = None\n",
    "        \n",
    "                        # Store as Rxiv\n",
    "                        else:\n",
    "                            # doi = re.search(doi_pattern, text)\n",
    "                            doi = matches[i]\n",
    "                            # DOI link provided\n",
    "                            if doi is not None:\n",
    "                                # rxiv_key[doi.group()].append(text)\n",
    "                                # rxiv_bioc[doi.group()] = None\n",
    "                                rxiv_key[doi].append(text)\n",
    "                                rxiv_bioc[doi] = None\n",
    "                            # DOI link not provided\n",
    "                            else: \n",
    "                                # rxiv_key[re.search(url_pattern, text).group()].append(text)\n",
    "                                # rxiv_bioc[re.search(url_pattern, text).group()] = None\n",
    "                                print(\"special case\")\n",
    "    \n",
    "                    # Check if the article is grey literature\n",
    "                    elif \"Grey literature\" in article_type[i]:\n",
    "                        # Search for url link\n",
    "                        # url = re.search(url_pattern, text)\n",
    "                        url = matches[i]\n",
    "                        if url is not None:\n",
    "                            # grey_key[url.group()].append(text)\n",
    "                            # grey_bioc[url.group()] = None\n",
    "                            grey_key[url].append(text)\n",
    "                            grey_bioc[url] = None\n",
    "                    \n",
    "                    # All other groups categorize as grey literature\n",
    "                    # else:\n",
    "                    #     url = re.search(url_pattern, text)\n",
    "                    #     if url is not None:\n",
    "                    #         grey_key[url.group()].append(text)\n",
    "                    #         grey_bioc[url.group()] = None\n",
    "\n",
    "    return publication_bioc, publication_key, rxiv_bioc, rxiv_key, grey_bioc, grey_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e9c7cc-28aa-4abb-a7cc-7c9cd942e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain BioC JSON file from PMID or PMC with a maximum of 3 API calls per second\n",
    "@sleep_and_retry\n",
    "@limits(calls=3, period=1)\n",
    "def get_pubtator_bioc_json(id):\n",
    "    # API link for BioC\n",
    "    url = \"https://www-ncbi-nlm-nih-gov.ezproxy.lib.ucalgary.ca/research/bionlp/RESTful/pmcoa.cgi/BioC_json/\" + str(id) + \"/unicode\"\n",
    "    bioc = requests.get(url, allow_redirects=True)\n",
    "\n",
    "    if bioc.status_code != 200:\n",
    "        raise ConnectionError('could not download {}\\nerror code: {}'.format(url, bioc.status_code))\n",
    "        return None\n",
    "\n",
    "    if bioc.content.decode('utf-8') == '[]':\n",
    "        return None\n",
    "    \n",
    "    return (bioc.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ab08e-a6b0-45d3-a711-ac39c9142417",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioc = get_pubtator_bioc_json(9005165)\n",
    "print(bioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed730892-c5e7-428c-ac33-51718d14b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain PMID ID from DOI link with a maximum of 3 API calls per second\n",
    "@sleep_and_retry\n",
    "@limits(calls=3, period=1)\n",
    "def get_pmid(doi):\n",
    "    # pmid = doi2pmid(doi)\n",
    "    doi_part = doi.split('doi.org/')[-1]\n",
    "\n",
    "    # Api link for paper details\n",
    "    api_link = 'https://www-ncbi-nlm-nih-gov.ezproxy.lib.ucalgary.ca/pmc/utils/idconv/v1.0/?tool=doi2pmid&email=david.yang1@ucalgary.ca&ids=' + doi_part\n",
    "    paper = requests.get(api_link)\n",
    "    soup = BeautifulSoup(paper.content, \"xml\")\n",
    "        \n",
    "    pmid = soup.find('record')['pmid']\n",
    "    return pmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f1cb8b-2020-43cc-89b3-a1864e05a894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata of Rxiv paper\n",
    "@sleep_and_retry\n",
    "@limits(calls=1, period=1)\n",
    "def get_rxiv_details(doi, is_biorxiv):\n",
    "    doi_part = doi.split('doi.org/')[-1]\n",
    "    \n",
    "    if is_biorxiv:\n",
    "        api_link = 'https://api.biorxiv.org/details/biorxiv/' + doi_part\n",
    "    else:\n",
    "        api_link = 'https://api.medrxiv.org/details/medrxiv/' + doi_part\n",
    "    \n",
    "    preprint_details = requests.get(api_link)\n",
    "    \n",
    "    if preprint_details.status_code != 200:\n",
    "        raise ConnectionError('could not download {}\\nerror code: {}'.format(api_link, preprint_details.status_code))\n",
    "        return None\n",
    "    \n",
    "    return preprint_details.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24f024-ce91-4221-a307-67b68d13b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PMID of Rxiv paper\n",
    "@sleep_and_retry\n",
    "@limits(calls=3, period=1)\n",
    "def get_rxiv_pmid(doi, is_biorxiv):\n",
    "    details = get_rxiv_details(doi,is_biorxiv).decode('utf-8')\n",
    "    pmid = None\n",
    "    \n",
    "    # Load the JSON data\n",
    "    data = json.loads(details)\n",
    "    title = data['collection'][0]['title']\n",
    "    modified_title = title.replace(\" \", \"%20\")\n",
    "    pubmed_link = \"http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&retmax=1000&term=\" + modified_title + \"&field=title\"\n",
    "    \n",
    "    data_json = requests.get(pubmed_link).content.decode('utf-8')\n",
    "    data = json.loads(data_json)\n",
    "    pmid = data['esearchresult']['idlist'][0]\n",
    "\n",
    "    return pmid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d3ba21-0d6f-4297-9a93-6f69e33cb127",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rxiv_published_doi(details):\n",
    "    data = json.loads(details)\n",
    "\n",
    "    # Check if it is published\n",
    "    if \"published\" in data[\"collection\"][0]:\n",
    "        doi = \"https://doi.org/\" + data['collection'][0]['published']\n",
    "        return doi\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ab00e9-6774-4e4e-a682-314dafa8e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rxiv_jats_xml(details):\n",
    "    data = json.loads(details)\n",
    "    \n",
    "    # Grab the JATS XML\n",
    "    jatsxml_url = data['collection'][0]['jatsxml']\n",
    "    jats_xml = requests.get(jatsxml_url).content.decode('utf-8')\n",
    "    return jats_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2b540-6ff4-4780-aa56-aea752859a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_jatsxml_to_html(input_file, output_file):\n",
    "    # dom = ET.parse(input_file)\n",
    "    dom = ET.fromstring(input_file)\n",
    "\n",
    "    # XSL style sheet\n",
    "    xslt = ET.parse('../data/other/jats-to-html.xsl')\n",
    "    transform = ET.XSLT(xslt)\n",
    "    newdom = transform(dom)\n",
    "    newdom.write_output(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e9d08-3dc9-40b9-a701-871b4bfcc919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_line_call(call):\n",
    "    x = call.split(\" \")\n",
    "    subprocess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b003c-a571-4dd2-965e-a5785a1e0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_journal_publication_bioc(dict, isPmidDict = False):\n",
    "    count = 0\n",
    "    unk_dict = {}\n",
    "    for key in dict:\n",
    "        rxiv = False\n",
    "        count += 1 \n",
    "\n",
    "        if count > 1000:\n",
    "            break\n",
    "        \n",
    "        bioc = None\n",
    "        \n",
    "        try:\n",
    "            # Convert to PMID\n",
    "            if isPmidDict:\n",
    "                pmid = key\n",
    "            else:\n",
    "                pmid = get_pmid(key)\n",
    "            bioc = get_pubtator_bioc_json(pmid)\n",
    "            if bioc == '[]':\n",
    "                bioc = None\n",
    "        except:\n",
    "            # Alternative way to get bioc\n",
    "            # print(key)\n",
    "            bioc = None\n",
    "            pass\n",
    "\n",
    "        if bioc is None:\n",
    "            try:\n",
    "                pmid = doi2pmid(doi)\n",
    "                bioc = get_pubtator_bioc_json(pmid)\n",
    "                if bioc == '[]':\n",
    "                    bioc = None\n",
    "            except:\n",
    "                # Alternative way to get bioc\n",
    "                # print(key)\n",
    "                bioc = None\n",
    "                pass\n",
    "\n",
    "        # Check if it is a preprint\n",
    "        if bioc is None or bioc == '[]':\n",
    "            unk_dict[key] = None\n",
    "            continue\n",
    "\n",
    "        dict[key] = bioc\n",
    "\n",
    "    for key in unk_dict:\n",
    "        dict.pop(key, None)\n",
    "        \n",
    "\n",
    "    return dict, unk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9463f-87a9-4de1-aa7c-2a10900141f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rxiv_bioc(dict):\n",
    "    count = 0\n",
    "    unk_dict = {}\n",
    "    for key in dict:\n",
    "        bioc = None\n",
    "        converted = False\n",
    "        biorxiv = True\n",
    "        details = None\n",
    "        \n",
    "        count += 1\n",
    "\n",
    "        if count > 100:\n",
    "            break\n",
    "        \n",
    "        # Get PMID as BioRxiv\n",
    "        try:\n",
    "            # Convert to PMID\n",
    "            pmid = get_rxiv_pmid(key, is_biorxiv=True)\n",
    "            bioc_temp = get_pubtator_bioc_json(pmid)\n",
    "            if bioc_temp != '[]' and bioc_temp is not None:\n",
    "                    bioc = bioc_temp\n",
    "                    converted = True\n",
    "        except:\n",
    "            # cannot_convert_m1 += 1\n",
    "            converted = False\n",
    "            # print(\"fail bio pmid\")\n",
    "            pass\n",
    "    \n",
    "        # Get PMID as MedRxiv\n",
    "        if converted == False:\n",
    "            try:\n",
    "                # Convert to PMID\n",
    "                pmid = get_rxiv_pmid(key, is_biorxiv=False)\n",
    "                bioc_temp = get_pubtator_bioc_json(pmid)\n",
    "                if bioc_temp != '[]' and bioc_temp is not None:\n",
    "                    bioc = bioc_temp\n",
    "                    converted = True\n",
    "            except:\n",
    "                # cannot_convert_m1 += 1\n",
    "                converted = False\n",
    "                # print(\"fail med pmid\")\n",
    "                pass\n",
    "\n",
    "        if converted == False:\n",
    "        # Convert to PMID then BioC using another tool\n",
    "            try:\n",
    "                # Convert to DOI then PMID then BioC\n",
    "                pmid = get_pmid(key)\n",
    "                bioc_temp = get_pubtator_bioc_json(pmid)\n",
    "                if bioc_temp != '[]' and bioc_temp is not None:\n",
    "                    bioc = bioc_temp\n",
    "                    converted = True\n",
    "            except:\n",
    "                # cannot_convert_m2 += 1\n",
    "                converted = False\n",
    "                # print(\"no doi\")\n",
    "                pass\n",
    "    \n",
    "        # Successful, goto next key\n",
    "        if bioc and bioc != \"[]\":\n",
    "            dict[key] = bioc\n",
    "            # print(\"done\")\n",
    "            continue\n",
    "    \n",
    "        # Try to get details as BioRxiv\n",
    "        try: \n",
    "            details = get_rxiv_details(key, is_biorxiv=True).decode('utf-8')\n",
    "    \n",
    "        except:\n",
    "            biorxiv = False\n",
    "            converted = False\n",
    "            # print(\"fail bio detail\")\n",
    "    \n",
    "        if details:\n",
    "            status = json.loads(details)\n",
    "            status = status['messages'][0]['status']\n",
    "    \n",
    "            if status != 'ok': \n",
    "                biorxiv = False\n",
    "        \n",
    "        # Try to get details as MedRxiv\n",
    "        if biorxiv == False:\n",
    "            try:\n",
    "                details = get_rxiv_details(key, is_biorxiv=False).decode('utf-8')\n",
    "            except:\n",
    "                # print(\"fail med detail\")\n",
    "                continue\n",
    "\n",
    "        if converted == False:\n",
    "        # Convert to PMID then BioC using another tool\n",
    "            try:\n",
    "                # Convert to DOI then PMID then BioC\n",
    "                doi = get_rxiv_published_doi(details)\n",
    "                pmid = get_pmid(doi)\n",
    "                bioc_temp = get_pubtator_bioc_json(pmid)\n",
    "                if bioc_temp != '[]' and bioc_temp is not None:\n",
    "                    bioc = bioc_temp\n",
    "                    converted = True\n",
    "            except:\n",
    "                # cannot_convert_m2 += 1\n",
    "                converted = False\n",
    "                # print(\"no published doi\")\n",
    "                pass\n",
    "    \n",
    "        # Retreive JATS XML then convert to HTML for later conversions\n",
    "        if converted == False or bioc == \"[]\":\n",
    "            try:\n",
    "                jats_xml = get_rxiv_jats_xml(details)\n",
    "                file_name = key.split('doi.org/')[-1]\n",
    "                # Replace . in DOI with -\n",
    "                file_name = file_name.replace(\".\", \"-\")\n",
    "                # Replace / in DOI with _\n",
    "                file_name = file_name.replace(\"/\", \"_\")\n",
    "                output_file = '../data/pokay/processed/html/' + file_name + \".html\"\n",
    "                convert_jatsxml_to_html(jats_xml, output_file)\n",
    "                bioc = \"converting\"\n",
    "            except:\n",
    "                bioc = None\n",
    "                # print(\"fail jats\")\n",
    "        \n",
    "        # Check if it is a preprint\n",
    "        if bioc is None or bioc == '[]':\n",
    "            unk_dict[key] = None\n",
    "            continue\n",
    "    \n",
    "        dict[key] = bioc\n",
    "\n",
    "    for key in unk_dict:\n",
    "        dict.pop(key, None)\n",
    "\n",
    "    return dict, unk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74a6419-2fb0-4092-9ffa-5be4c56aeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(key):\n",
    "    doi = re.search(doi_pattern, key)\n",
    "\n",
    "    if doi is not None:\n",
    "        file_name = key.split('doi.org/')[-1]\n",
    "    else:\n",
    "        key = key.split('https://')[-1]\n",
    "        file_name = key\n",
    "\n",
    "    # Replace . in DOI with -\n",
    "    file_name = file_name.replace(\".\", \"-\")\n",
    "    # Replace / in DOI with _\n",
    "    file_name = file_name.replace(\"/\", \"_\")\n",
    "    # file_name += \".pdf\"\n",
    "\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff7cca-47c6-4644-9681-cd520f0f5ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "from bioc import biocjson\n",
    "import pandas as pd\n",
    "import pypdf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70055faa-4c32-47c7-8391-c7ab8f5d9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions\n",
    "one_letter_aa_change = r'\\b([ARNDCQEGHILKMFPSTWYV])([1-9]+\\d*)(del|(?!\\1)[ARNDCQEGHILKMFPSTWYV])\\b'\n",
    "# three_letter_aa_change = r'\\b(?:ALA|ARG|ASN|ASP|CYS|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL)[1-9]+\\d*(?:ALA|ARG|ASN|ASP|CYS|DEL|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VA|DEL)\\b'\n",
    "# three_letter_aa_change = r'\\b((?:ALA|ARG|ASN|ASP|CYS|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL))(([1-9]+\\d*)(?!\\1)(?:ALA|ARG|ASN|ASP|CYS|DEL|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL)\\b'\n",
    "three_letter_aa_change = r'\\b((?:ALA|ARG|ASN|ASP|CYS|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL))([1-9]+\\d*)(?!(\\1))(ALA|ARG|ASN|ASP|CYS|DEL|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL)\\b'\n",
    "genome_change = r'\\bg\\.[ATGCU][1-9]+\\d*[ATGCU]\\b'\n",
    "genome_change_alt =  r'\\bg\\.[1-9]+\\d*[ATGCU]\\>[ATGCU]\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a901b0-c876-4202-84f9-40dcb00a4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dictionary(d):\n",
    "    print(\"size: \" + str(len(d)))\n",
    "    for key in d:\n",
    "        if d[key] is None:\n",
    "            print(\"None: \" + key)\n",
    "    \n",
    "        if d[key] == \"converting\":\n",
    "            print(\"Converting: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d7c6e-b799-4d37-98c8-307e03dea4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove papers that are in pokay database\n",
    "\n",
    "def related_paper(paper):\n",
    "    try:\n",
    "        doi = paper[\"passages\"][0]['infons']['article-id_doi']\n",
    "        \n",
    "        if doi in pokay_data:\n",
    "            return True\n",
    "            \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    return False\n",
    "\n",
    "# filtered_papers_copy = [x for x in filtered_papers if not related_paper(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03e19ab-7e69-460f-823e-bdfc4c14241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grab subsample from data\n",
    "def subset_sample(original, n):\n",
    "    sub = []\n",
    "    df = copy.deepcopy(original)\n",
    "    random.seed(42)\n",
    "    random.shuffle(df)\n",
    "    \n",
    "    for i in range(n):\n",
    "        entry = df.pop(-1)\n",
    "        sub.append(entry)\n",
    "\n",
    "    return df, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f07ed9-8759-41ab-b2c2-1e8560503ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to un-nest data. Example JSON file will contain Key1: {Key 2: {Key3: Val}}  \n",
    "def extract_nested_elements(input_string):\n",
    "    elements = []\n",
    "    start = 0\n",
    "    brace_count = 0\n",
    "    inside_element = False\n",
    "\n",
    "    for i, char in enumerate(input_string):\n",
    "        if char == '{':\n",
    "            if brace_count == 0:\n",
    "                start = i\n",
    "                inside_element = True\n",
    "            brace_count += 1\n",
    "        elif char == '}':\n",
    "            brace_count -= 1\n",
    "            if brace_count == 0 and inside_element:\n",
    "                elements.append(input_string[start:i+1])\n",
    "                inside_element = False\n",
    "\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f434159-2bed-4fc0-b025-6ae51d750a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from training data (litcovid portion), passes DOI, output is dictionary \n",
    "def litcovid_text_extract(data):\n",
    "    count = 0\n",
    "    out = {}\n",
    "    for paper in data:\n",
    "        try:\n",
    "            passage = paper[\"passages\"]\n",
    "            pmid = paper[\"pmid\"]\n",
    "        except:\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "        text = \"\"\n",
    "        \n",
    "        for section in passage:\n",
    "            try:\n",
    "                text += section['text']\n",
    "        \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if text[-1].isalnum(): \n",
    "                text += \". \"\n",
    "            else:\n",
    "                text += \" \"\n",
    "\n",
    "        out[pmid] = text\n",
    "        \n",
    "    # print(count)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f98d0-9661-4d2a-86c8-91fd4484470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab file name from DOI\n",
    "def get_file_name(key):\n",
    "    doi_pattern = r'https:\\/\\/doi\\.org\\/[\\w/.-]+'\n",
    "    doi = re.search(doi_pattern, key)\n",
    "\n",
    "    if doi is not None:\n",
    "        file_name = key.split('doi.org/')[-1]\n",
    "    else:\n",
    "        key = key.split('https://')[-1]\n",
    "        file_name = key\n",
    "\n",
    "    # Replace . in DOI with -\n",
    "    file_name = file_name.replace(\".\", \"-\")\n",
    "    # Replace / in DOI with _\n",
    "    file_name = file_name.replace(\"/\", \"_\")\n",
    "    # file_name += \".pdf\"\n",
    "\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09b94bc-2da8-4bcf-b03e-10fb8596a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text extract of JSON from pubtator API\n",
    "def pubtator_extract(paper):\n",
    "    text = \"\"\n",
    "    paper = paper[1:-1]\n",
    "\n",
    "    try:\n",
    "        bioc_list = extract_nested_elements(paper)\n",
    "        \n",
    "        bioc_collection = biocjson.loads(bioc_list[-1])\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    for document in bioc_collection.documents:    \n",
    "        for passage in document.passages:\n",
    "            try:\n",
    "                text += passage.text\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if text[-1].isalnum(): \n",
    "                text += \". \"\n",
    "            else:\n",
    "                text += \" \"\n",
    "   \n",
    "    if text == \"\":\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98b179-ae45-4f04-8c9b-1c1d59344bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text extract of JSON from conversions of JATS XML\n",
    "def jats_extract(paper):\n",
    "    text = \"\"\n",
    "    \n",
    "    try:\n",
    "        paper_copy = paper[1:-1]\n",
    "        bioc_collection = biocjson.loads(paper_copy)\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            bioc_collection = biocjson.loads(paper)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    for document in bioc_collection.documents:    \n",
    "        for passage in document.passages:\n",
    "            try:\n",
    "                text += passage.text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if text[-1].isalnum(): \n",
    "                text += \". \"\n",
    "            else:\n",
    "                text += \" \"\n",
    "\n",
    "    if text == \"\":\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff27505f-d3f7-4bf5-87a9-c74c2891516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text extract of JSON from conversions of PDF\n",
    "def pdf_extract(data):\n",
    "    text = \"\"\n",
    "\n",
    "    try:\n",
    "        bioc_collection = biocjson.loads(paper)\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "    for document in bioc_collection.documents:    \n",
    "        for passage in document.passages:\n",
    "            try:\n",
    "                text += passage.text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if text[-1].isalnum(): \n",
    "                text += \". \"\n",
    "            else:\n",
    "                text += \" \"\n",
    "\n",
    "    if text == \"\":\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ffc7b-2c29-472f-bf52-06e80e94fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pokay text from each individual pokay paper\n",
    "def pokay_text_extract(paper):\n",
    "    text_extracted = False\n",
    "    text = \"\"\n",
    "    \n",
    "    if paper is not None:\n",
    "        # Try to extract as pubtator\n",
    "        try:\n",
    "            text = pubtator_extract(paper)\n",
    "\n",
    "            if text is not None:\n",
    "                text_extracted = True\n",
    "                pokay_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if text_extracted:\n",
    "            return text\n",
    "\n",
    "        # Try to extract as JATS\n",
    "        try:\n",
    "            text = jats_extract(paper)\n",
    "\n",
    "            if text is not None:\n",
    "                text_extracted = True\n",
    "                pokay_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if text_extracted:\n",
    "            return text\n",
    "\n",
    "        # Try to extract as PDF\n",
    "        try:\n",
    "            text = pdf_extract(paper)\n",
    "\n",
    "            if text is not None:\n",
    "                text_extracted = True\n",
    "                pokay_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        file = get_file_name(key)\n",
    "        file = \"/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/\" + file + \".pdf\"\n",
    "        isExist = os.path.exists(file) \n",
    "        if isExist:\n",
    "            print(file)\n",
    "            reader = pypdf.PdfReader(file)\n",
    "    \n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7843d0-2738-48c6-b400-0aec53fac0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final function to handle all cases for pokay data\n",
    "def pokay_extract(data):\n",
    "    pokay_text = []\n",
    "\n",
    "    for key in data:\n",
    "        paper = data[key]\n",
    "        text_extracted = False\n",
    "        text = \"\"\n",
    "        \n",
    "        if paper is not None:\n",
    "            # Try to extract as pubtator\n",
    "            try:\n",
    "                text = pubtator_extract(paper)\n",
    "    \n",
    "                if text is not None:\n",
    "                    text_extracted = True\n",
    "                    pokay_text.append(text)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            if text_extracted:\n",
    "                continue\n",
    "    \n",
    "            # Try to extract as JATS\n",
    "            try:\n",
    "                text = jats_extract(paper)\n",
    "    \n",
    "                if text is not None:\n",
    "                    text_extracted = True\n",
    "                    pokay_text.append(text)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "            if text_extracted:\n",
    "                continue\n",
    "    \n",
    "            # Try to extract as PDF\n",
    "            try:\n",
    "                text = pdf_extract(paper)\n",
    "    \n",
    "                if text is not None:\n",
    "                    text_extracted = True\n",
    "                    pokay_text.append(text)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        else:\n",
    "            file = get_file_name(key)\n",
    "            file = \"/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/\" + file + \".pdf\"\n",
    "            isExist = os.path.exists(file) \n",
    "            if isExist:\n",
    "                print(file)\n",
    "                reader = pypdf.PdfReader(file)\n",
    "        \n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text()\n",
    "        \n",
    "                if text != \"\":\n",
    "                    pokay_text.append(text)\n",
    "    \n",
    "    return pokay_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0891f5-a258-430b-920c-f00831524b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label each text in dataframe\n",
    "def get_label(df, column):\n",
    "    label_input=[]\n",
    "    for i in df[column]:\n",
    "        print(i)\n",
    "        \n",
    "        while True:\n",
    "            label = int(input('Does this relate to viral variants? (0 = No, 1 = Yes)'))\n",
    "            if label == 0 or label == 1:\n",
    "                break\n",
    "            \n",
    "        label_input.append(label)\n",
    "        print(\" \")\n",
    "    df['label'] = label_input\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
